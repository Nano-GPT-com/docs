{
  "openapi": "3.1.0",
  "info": {
    "title": "NanoGPT API",
    "description": "API documentation for the NanoGPT language, image, video, speech-to-text, and text-to-speech generation services",
    "license": {
      "name": "MIT"
    },
    "version": "1.0.0"
  },
  "servers": [
    {
      "url": "https://nano-gpt.com/api",
      "description": "NanoGPT API Server"
    }
  ],
  "paths": {
    "/v1/chat/completions": {
      "post": {
        "description": "Creates a chat completion for the provided messages",
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "requestBody": {
          "description": "Parameters for chat completion",
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/ChatCompletionRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Chat completion response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ChatCompletionResponse"
                }
              }
            }
          },
          "400": {
            "description": "Unexpected error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/v1/completions": {
      "post": {
        "description": "Creates a completion for the provided prompt",
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "requestBody": {
          "description": "Parameters for text completion",
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/CompletionRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Text completion response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/CompletionResponse"
                }
              }
            }
          },
          "400": {
            "description": "Unexpected error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/generate-image": {
      "post": {
        "description": "Generates an image from a text prompt",
        "security": [
          {
            "apiKeyAuth": []
          }
        ],
        "requestBody": {
          "description": "Parameters for image generation",
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/ImageGenerationRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Image generation response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ImageGenerationResponse"
                }
              }
            }
          },
          "400": {
            "description": "Unexpected error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/talk-to-gpt": {
      "post": {
        "description": "Legacy endpoint for chat interactions with the GPT model",
        "security": [
          {
            "apiKeyAuth": []
          }
        ],
        "requestBody": {
          "description": "Parameters for talking to GPT",
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/TalkToGptRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Talk to GPT response",
            "content": {
              "text/plain": {
                "schema": {
                  "type": "string",
                  "description": "Text response followed by metadata in <NanoGPT> tags"
                }
              }
            }
          },
          "400": {
            "description": "Unexpected error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/v1/models": {
      "get": {
        "description": "List available models with optional detailed information including pricing",
        "security": [
          {
            "bearerAuth": []
          },
          {
            "apiKeyAuth": []
          }
        ],
        "parameters": [
          {
            "name": "detailed",
            "in": "query",
            "description": "Returns detailed model information including pricing",
            "required": false,
            "schema": {
              "type": "boolean",
              "default": false
            }
          }
        ],
        "responses": {
          "200": {
            "description": "List of available models",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ModelsResponse"
                }
              }
            }
          },
          "400": {
            "description": "Unexpected error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/models": {
      "get": {
        "description": "Legacy endpoint to list available models",
        "security": [
          {
            "apiKeyAuth": []
          }
        ],
        "responses": {
          "200": {
            "description": "List of available models (legacy format)",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ModelsLegacyResponse"
                }
              }
            }
          },
          "400": {
            "description": "Unexpected error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/check-balance": {
      "post": {
        "description": "Check the account balance",
        "security": [
          {
            "apiKeyAuth": []
          }
        ],
        "responses": {
          "200": {
            "description": "Account balance information",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/BalanceResponse"
                }
              }
            }
          },
          "400": {
            "description": "Unexpected error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/check-midjourney-status": {
      "post": {
        "description": "Check the status of an asynchronous Midjourney image generation task",
        "security": [
          {
            "apiKeyAuth": []
          }
        ],
        "requestBody": {
          "description": "Task ID to check status for",
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/CheckMidjourneyStatusRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Midjourney task status response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/CheckMidjourneyStatusResponse"
                }
              }
            }
          },
          "400": {
            "description": "Bad Request (e.g., missing task_id)",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          },
          "401": {
            "description": "Unauthorized (invalid API key)"
          }
        }
      }
    },
    "/receive-nano": {
      "post": {
        "description": "Process pending Nano transactions for the account",
        "security": [
          {
            "apiKeyAuth": []
          }
        ],
        "responses": {
          "200": {
            "description": "Nano receive operation result",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ReceiveNanoResponse"
                }
              }
            }
          },
          "400": {
            "description": "Unexpected error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/generate-video": {
      "post": {
        "description": "Generate videos using various AI models including text-to-video and image-to-video capabilities across multiple providers (FAL, PromptChan, LongStories). Model capabilities: **LongStories** (longstories, longstories-kids): AI-powered short-form video creation with script generation, voice narration, and automated editing. **FAL Models**: kling-video (Kling 1.5 Pro text-to-video), kling-video-v2 (Kling 2.0 text/image-to-video), veo2-video (Veo2 text/image-to-video), minimax-video (MiniMax T2V-01), hunyuan-video (Hunyuan text-to-video), hunyuan-video-image-to-video (Hunyuan image-to-video), wan-video-image-to-video (Wan image-to-video), kling-v21-standard/pro/master (Kling V2.1 variants). **PromptChan**: promptchan-video (adult content generation). All requests return immediately with status 'pending' - use the unified status endpoint to poll for completion.",
        "security": [
          {
            "apiKeyAuth": []
          }
        ],
        "requestBody": {
          "description": "Parameters for video generation across different models and providers",
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/VideoGenerationRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "202": {
            "description": "Video generation request submitted successfully (asynchronous processing)",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/VideoGenerationResponse"
                }
              }
            }
          },
          "400": {
            "description": "Bad Request - Invalid parameters or safety filter triggered",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          },
          "401": {
            "description": "Unauthorized - Invalid or missing API key"
          },
          "500": {
            "description": "Server Error - Video generation failed",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/v1/video/status": {
      "get": {
        "description": "Check the status of a video generation request",
        "security": [
          {
            "apiKeyAuth": []
          }
        ],
        "parameters": [
          {
            "name": "runId",
            "in": "query",
            "description": "Run ID from the generation request",
            "required": true,
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "projectId",
            "in": "query",
            "description": "Project ID from the generation request",
            "required": true,
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "cost",
            "in": "query",
            "description": "Cost of the video generation",
            "required": false,
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "paymentSource",
            "in": "query",
            "description": "Payment source used",
            "required": false,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "description": "Video generation status",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/VideoStatusResponse"
                }
              }
            }
          },
          "400": {
            "description": "Unexpected error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/api/video/status": {
      "get": {
        "description": "Unified video status endpoint that works with any provider. Check the status of a video generation request using only the request ID - the system automatically determines the provider and returns normalized status information.",
        "security": [
          {
            "apiKeyAuth": []
          }
        ],
        "parameters": [
          {
            "name": "requestId",
            "in": "query",
            "description": "The unique request ID returned from any video generation endpoint",
            "required": true,
            "schema": {
              "type": "string"
            },
            "example": "fal-1234567890"
          }
        ],
        "responses": {
          "200": {
            "description": "Unified video generation status",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/UnifiedVideoStatusResponse"
                }
              }
            }
          },
          "400": {
            "description": "Bad Request - Missing requestId parameter",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          },
          "404": {
            "description": "Video generation request not found",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          },
          "500": {
            "description": "Server Error - Failed to check video generation status",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/v1/images/generations": {
      "servers": [
        {
          "url": "https://nano-gpt.com",
          "description": "Root server for OpenAI-compatible endpoints"
        }
      ],
      "post": {
        "description": "Creates an image generation for the provided prompt (OpenAI-compatible)",
        "security": [
          { "bearerAuth": [] }
        ],
        "requestBody": {
          "description": "Parameters for image generation",
          "required": true,
          "content": {
            "application/json": {
              "schema": { "$ref": "#/components/schemas/OpenAIImageGenerationsRequest" }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Image generation response",
            "content": {
              "application/json": {
                "schema": { "$ref": "#/components/schemas/OpenAIImageGenerationsResponse" }
              }
            }
          },
          "400": {
            "description": "Unexpected error",
            "content": {
              "application/json": {
                "schema": { "$ref": "#/components/schemas/Error" }
              }
            }
          }
        }
      }
    },
    "/api/v1/tee/attestation": {
      "servers": [
        { "url": "https://nano-gpt.com", "description": "Root server for TEE endpoints" }
      ],
      "get": {
        "description": "Fetch TEE attestation report for a model",
        "security": [ { "bearerAuth": [] } ],
        "parameters": [
          { "name": "model", "in": "query", "description": "TEE model to attest", "required": true, "schema": { "type": "string" } }
        ],
        "responses": {
          "200": {
            "description": "TEE attestation report",
            "content": { "application/json": { "schema": { "$ref": "#/components/schemas/TEEAttestationResponse" } } }
          },
          "400": { "description": "Bad Request", "content": { "application/json": { "schema": { "$ref": "#/components/schemas/Error" } } } },
          "401": { "description": "Unauthorized" },
          "500": { "description": "Server Error" }
        }
      }
    },
    "/api/v1/tee/signature/{requestId}": {
      "servers": [
        { "url": "https://nano-gpt.com", "description": "Root server for TEE endpoints" }
      ],
      "get": {
        "description": "Fetch ECDSA signature for a chat request",
        "security": [ { "bearerAuth": [] } ],
        "parameters": [
          { "name": "requestId", "in": "path", "description": "Chat request ID", "required": true, "schema": { "type": "string" } },
          { "name": "model", "in": "query", "description": "TEE model to attest", "required": true, "schema": { "type": "string" } },
          { "name": "signing_algo", "in": "query", "description": "Signing algorithm to use", "required": false, "schema": { "type": "string" }, "example": "ecdsa" }
        ],
        "responses": {
          "200": {
            "description": "TEE signature response",
            "content": { "application/json": { "schema": { "$ref": "#/components/schemas/TEESignatureResponse" } } }
          },
          "400": { "description": "Bad Request", "content": { "application/json": { "schema": { "$ref": "#/components/schemas/Error" } } } },
          "401": { "description": "Unauthorized" },
          "500": { "description": "Server Error" }
        }
      }
    },
    "/api/transcribe": {
      "post": {
        "description": "Transcribe audio files into text using state-of-the-art speech recognition models. Supports multiple languages, speaker diarization, and various audio formats. Returns synchronous results for Whisper/Wizper models and asynchronous job IDs for Elevenlabs-STT.",
        "security": [
          {
            "apiKeyAuth": []
          }
        ],
        "requestBody": {
          "description": "Audio transcription parameters. Use multipart/form-data for file uploads or application/json for URL-based requests.",
          "content": {
            "multipart/form-data": {
              "schema": {
                "$ref": "#/components/schemas/TranscribeFormRequest"
              }
            },
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/TranscribeJsonRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Synchronous transcription response (Whisper/Wizper models)",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/TranscribeResponse"
                }
              }
            }
          },
          "202": {
            "description": "Asynchronous transcription job started (Elevenlabs-STT model)",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/TranscribeAsyncResponse"
                }
              }
            }
          },
          "400": {
            "description": "Bad Request - Invalid parameters or file format",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          },
          "401": {
            "description": "Unauthorized - Invalid or missing API key"
          },
          "402": {
            "description": "Payment Required - Insufficient balance",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          },
          "413": {
            "description": "Payload Too Large - File exceeds size limit",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          },
          "500": {
            "description": "Internal Server Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/api/transcribe/status": {
      "post": {
        "description": "Check the status of an asynchronous transcription job (Elevenlabs-STT). Poll this endpoint to get the transcription results when the job is completed.",
        "security": [
          {
            "apiKeyAuth": []
          }
        ],
        "requestBody": {
          "description": "Status check parameters including runId from the initial transcription request",
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/TranscribeStatusRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Transcription status response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/TranscribeStatusResponse"
                }
              }
            }
          },
          "400": {
            "description": "Bad Request - Missing required parameters",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          },
          "401": {
            "description": "Unauthorized - Invalid or missing API key"
          },
          "404": {
            "description": "Not Found - Transcription job not found",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          },
          "500": {
            "description": "Internal Server Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/api/youtube-transcribe": {
      "post": {
        "description": "Extract transcripts from YouTube videos programmatically. Supports multiple URLs per request and provides detailed response information including success/failure status for each video.",
        "security": [
          {
            "apiKeyAuth": []
          }
        ],
        "requestBody": {
          "description": "YouTube transcription parameters",
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/YouTubeTranscribeRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "YouTube transcription response with results for each URL",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/YouTubeTranscribeResponse"
                }
              }
            }
          },
          "400": {
            "description": "Bad Request - Please provide an array of YouTube URLs",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          },
          "401": {
            "description": "Unauthorized - Invalid session or API key"
          },
          "402": {
            "description": "Payment Required - Insufficient balance",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          },
          "429": {
            "description": "Too Many Requests - Rate limit exceeded",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          },
          "500": {
            "description": "Internal Server Error"
          }
        }
      }
    },
    "/api/tts": {
      "post": {
        "description": "Convert text into natural-sounding speech using various TTS models from different providers. Supports multiple languages, voices, and customization options including speed control, voice instructions, and audio format selection.",
        "security": [
          {
            "apiKeyAuth": []
          }
        ],
        "requestBody": {
          "description": "Text-to-speech generation parameters",
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/TTSRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Text-to-speech response. Returns either JSON with audio URL or binary audio data depending on the model.",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/TTSResponse"
                }
              },
              "audio/mp3": {
                "schema": {
                  "type": "string",
                  "format": "binary",
                  "description": "Binary audio data (for OpenAI models)"
                }
              },
              "audio/wav": {
                "schema": {
                  "type": "string",
                  "format": "binary",
                  "description": "Binary audio data"
                }
              },
              "audio/opus": {
                "schema": {
                  "type": "string",
                  "format": "binary",
                  "description": "Binary audio data (OpenAI models)"
                }
              },
              "audio/aac": {
                "schema": {
                  "type": "string",
                  "format": "binary",
                  "description": "Binary audio data (OpenAI models)"
                }
              },
              "audio/flac": {
                "schema": {
                  "type": "string",
                  "format": "binary",
                  "description": "Binary audio data (OpenAI models)"
                }
              }
            }
          },
          "400": {
            "description": "Bad Request - Invalid parameters or missing text",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          },
          "401": {
            "description": "Unauthorized - Invalid or missing API key"
          },
          "402": {
            "description": "Payment Required - Insufficient balance",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          },
          "413": {
            "description": "Payload Too Large - Text exceeds model limits",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          },
          "429": {
            "description": "Too Many Requests - Rate limit exceeded",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          },
          "501": {
            "description": "Not Implemented - Model not yet implemented",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          },
          "500": {
            "description": "Internal Server Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "ChatCompletionRequest": {
        "type": "object",
        "required": [
          "model",
          "messages"
        ],
        "properties": {
          "model": {
            "type": "string",
            "description": "The model to use for completion. Append ':online' for web search ($0.005/request) or ':online/linkup-deep' for deep web search ($0.05/request)",
            "default": "chatgpt-4o-latest",
            "examples": ["chatgpt-4o-latest", "chatgpt-4o-latest:online", "chatgpt-4o-latest:online/linkup-deep", "claude-3-5-sonnet-20241022:online"]
          },
          "messages": {
            "type": "array",
            "description": "Array of message objects with role and content",
            "default": [
              {
                "role": "user",
                "content": "Testing, please reply!"
              }
            ],
            "items": {
              "type": "object",
              "required": [
                "role",
                "content"
              ],
              "properties": {
                "role": {
                  "type": "string",
                  "description": "The role of the message author",
                  "enum": ["system", "user", "assistant"]
                },
                "content": {
                  "type": "string",
                  "description": "The content of the message"
                }
              }
            }
          },
          "stream": {
            "type": "boolean",
            "description": "Whether to stream the response",
            "default": false
          },
          "temperature": {
            "type": "number",
            "description": "Controls randomness (0-2)",
            "default": 0.7
          },
          "max_tokens": {
            "type": "integer",
            "description": "Maximum number of tokens to generate",
            "default": 4000
          },
          "top_p": {
            "type": "number",
            "description": "Nucleus sampling parameter (0-1)",
            "default": 1
          },
          "frequency_penalty": {
            "type": "number",
            "description": "Penalty for frequency of tokens (-2 to 2)",
            "default": 0
          },
          "presence_penalty": {
            "type": "number",
            "description": "Penalty for presence of tokens (-2 to 2)",
            "default": 0
          },
          "cache_control": {
            "type": "object",
            "description": "Cache control settings for Claude models only",
            "properties": {
              "enabled": {
                "type": "boolean",
                "description": "Whether to enable caching",
                "default": false
              },
              "ttl": {
                "type": "string",
                "description": "Cache time-to-live ('5m', '1h')",
                "example": "5m"
              }
            }
          }
        }
      },
      "ChatCompletionResponse": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "Unique identifier for the completion"
          },
          "object": {
            "type": "string",
            "description": "Object type, always 'chat.completion'"
          },
          "created": {
            "type": "integer",
            "description": "Unix timestamp of when the completion was created"
          },
          "choices": {
            "type": "array",
            "description": "Array of completion choices",
            "items": {
              "type": "object",
              "properties": {
                "index": {
                  "type": "integer",
                  "description": "Index of the choice"
                },
                "message": {
                  "type": "object",
                  "properties": {
                    "role": {
                      "type": "string",
                      "description": "Role of the completion message",
                      "enum": ["assistant"]
                    },
                    "content": {
                      "type": "string",
                      "description": "Content of the completion message"
                    }
                  }
                },
                "finish_reason": {
                  "type": "string",
                  "description": "Reason why the completion finished",
                  "enum": ["stop", "length", "content_filter"]
                }
              }
            }
          },
          "usage": {
            "type": "object",
            "properties": {
              "prompt_tokens": {
                "type": "integer",
                "description": "Number of tokens in the prompt"
              },
              "completion_tokens": {
                "type": "integer",
                "description": "Number of tokens in the completion"
              },
              "total_tokens": {
                "type": "integer",
                "description": "Total number of tokens used"
              }
            }
          }
        }
      },
      "CompletionRequest": {
        "type": "object",
        "required": [
          "model",
          "prompt"
        ],
        "properties": {
          "model": {
            "type": "string",
            "description": "The model to use for completion. Append ':online' for web search ($0.005/request) or ':online/linkup-deep' for deep web search ($0.05/request)",
            "default": "chatgpt-4o-latest",
            "examples": ["chatgpt-4o-latest", "chatgpt-4o-latest:online", "chatgpt-4o-latest:online/linkup-deep", "claude-3-5-sonnet-20241022:online"]
          },
          "prompt": {
            "type": "string",
            "description": "The text prompt to complete"
          },
          "max_tokens": {
            "type": "integer",
            "description": "Maximum number of tokens to generate",
            "default": 4000
          },
          "temperature": {
            "type": "number",
            "description": "Controls randomness (0-2)",
            "default": 0.7
          },
          "top_p": {
            "type": "number",
            "description": "Nucleus sampling parameter (0-1)",
            "default": 1
          },
          "stream": {
            "type": "boolean",
            "description": "Whether to stream the response",
            "default": false
          },
          "stop": {
            "oneOf": [
              {
                "type": "string"
              },
              {
                "type": "array",
                "items": {
                  "type": "string"
                }
              }
            ],
            "description": "Up to 4 sequences where the API will stop generating"
          },
          "frequency_penalty": {
            "type": "number",
            "description": "Penalty for frequency of tokens (-2 to 2)",
            "default": 0
          },
          "presence_penalty": {
            "type": "number",
            "description": "Penalty for presence of tokens (-2 to 2)",
            "default": 0
          }
        }
      },
      "CompletionResponse": {
        "type": "object",
        "properties": {
          "id": {
            "type": "string",
            "description": "Unique identifier for the completion"
          },
          "object": {
            "type": "string",
            "description": "Object type, always 'text_completion'"
          },
          "created": {
            "type": "integer",
            "description": "Unix timestamp of when the completion was created"
          },
          "model": {
            "type": "string",
            "description": "Model used for completion"
          },
          "choices": {
            "type": "array",
            "description": "Array of completion choices",
            "items": {
              "type": "object",
              "properties": {
                "text": {
                  "type": "string",
                  "description": "The completed text"
                },
                "index": {
                  "type": "integer",
                  "description": "Index of the choice"
                },
                "logprobs": {
                  "type": "object",
                  "nullable": true,
                  "description": "Log probabilities of tokens (if requested)"
                },
                "finish_reason": {
                  "type": "string",
                  "description": "Reason why the completion finished",
                  "enum": ["stop", "length", "content_filter"]
                }
              }
            }
          },
          "usage": {
            "type": "object",
            "properties": {
              "prompt_tokens": {
                "type": "integer",
                "description": "Number of tokens in the prompt"
              },
              "completion_tokens": {
                "type": "integer",
                "description": "Number of tokens in the completion"
              },
              "total_tokens": {
                "type": "integer",
                "description": "Total number of tokens used"
              }
            }
          }
        }
      },
      "ImageGenerationRequest": {
        "type": "object",
        "required": [
          "prompt",
          "model"
        ],
        "properties": {
          "prompt": {
            "type": "string",
            "description": "The text description of the image to generate",
            "example": "RAW photo, a portrait photo of a latina woman in casual clothes, natural skin, 8k uhd, high quality, film grain, Fujifilm XT3"
          },
          "model": {
            "type": "string",
            "description": "The model to use for generation",
            "default": "recraft-v3"
          },
          "width": {
            "type": "integer",
            "description": "Width of the generated image",
            "default": 1024
          },
          "height": {
            "type": "integer",
            "description": "Height of the generated image",
            "default": 1024
          },
          "negative_prompt": {
            "type": "string",
            "description": "Things to avoid in the generated image"
          },
          "nImages": {
            "type": "integer",
            "description": "Number of images to generate",
            "default": 1
          },
          "num_steps": {
            "type": "integer",
            "description": "Number of denoising steps",
            "default": 10
          },
          "resolution": {
            "type": "string",
            "description": "Output resolution",
            "default": "1024x1024"
          },
          "sampler_name": {
            "type": "string",
            "description": "Sampling method"
          },
          "scale": {
            "type": "number",
            "description": "Guidance scale",
            "default": 7.5
          }
        }
      },
      "ImageGenerationResponse": {
        "type": "object",
        "properties": {
          "image": {
            "type": "string",
            "description": "Base64 encoded image data"
          },
          "cost": {
            "type": "number",
            "description": "Cost of the generation"
          },
          "inputTokens": {
            "type": "integer",
            "description": "Number of input tokens used"
          },
          "outputTokens": {
            "type": "integer",
            "description": "Number of output tokens used"
          }
        }
      },
      "Error": {
        "required": [
          "error",
          "message"
        ],
        "type": "object",
        "properties": {
          "error": {
            "type": "integer",
            "format": "int32"
          },
          "message": {
            "type": "string"
          }
        }
      },
      "TalkToGptRequest": {
        "type": "object",
        "required": [
          "model"
        ],
        "properties": {
          "prompt": {
            "type": "string",
            "description": "The text prompt to send to GPT (optional)",
            "default": "",
            "example": "Please explain the concept of artificial intelligence."
          },
          "model": {
            "type": "string",
            "description": "The model to use for generation. Append ':online' for web search ($0.005/request) or ':online/linkup-deep' for deep web search ($0.05/request)",
            "default": "chatgpt-4o-latest",
            "examples": ["chatgpt-4o-latest", "chatgpt-4o-latest:online", "claude-3-5-sonnet-20241022:online/linkup-deep"]
          },
          "messages": {
            "type": "array",
            "description": "Array of previous message objects for context (optional)",
            "default": [
              {
                "role": "user",
                "content": "Hi, I'm just testing!"
              }
            ],
            "items": {
              "type": "object",
              "required": [
                "role",
                "content"
              ],
              "properties": {
                "role": {
                  "type": "string", 
                  "description": "The role of the message author",
                  "enum": ["user", "assistant"]
                },
                "content": {
                  "type": "string",
                  "description": "The content of the message"
                }
              }
            }
          }
        }
      },
      "ModelsResponse": {
        "type": "object",
        "properties": {
          "object": {
            "type": "string",
            "description": "Type of object, always 'list' for the models response",
            "default": "list"
          },
          "data": {
            "type": "array",
            "description": "List of available models",
            "items": {
              "type": "object",
              "properties": {
                "id": {
                  "type": "string",
                  "description": "Unique identifier for the model",
                  "example": "chatgpt-4o-latest"
                },
                "object": {
                  "type": "string",
                  "description": "Type of object, always 'model'",
                  "default": "model"
                },
                "created": {
                  "type": "integer",
                  "description": "Unix timestamp when the model was created"
                },
                "owned_by": {
                  "type": "string",
                  "description": "Organization that owns the model",
                  "example": "openai"
                },
                "name": {
                  "type": "string",
                  "description": "Human-readable model name (detailed mode only)",
                  "example": "GPT-4o Mini"
                },
                "description": {
                  "type": "string",
                  "description": "Detailed model description (detailed mode only)",
                  "example": "OpenAI's affordable and intelligent small model for fast, lightweight tasks"
                },
                "context_length": {
                  "type": "integer",
                  "description": "Maximum input tokens (detailed mode only, null if not available)",
                  "example": 128000
                },
                "pricing": {
                  "type": "object",
                  "description": "Pricing information object (detailed mode only)",
                  "properties": {
                    "prompt": {
                      "type": "number",
                      "description": "Cost per million input tokens in USD",
                      "example": 0.00015
                    },
                    "completion": {
                      "type": "number",
                      "description": "Cost per million output tokens in USD",
                      "example": 0.0006
                    },
                    "currency": {
                      "type": "string",
                      "description": "Always 'USD'",
                      "default": "USD"
                    },
                    "unit": {
                      "type": "string",
                      "description": "Always 'per_million_tokens'",
                      "default": "per_million_tokens"
                    }
                  }
                }
              }
            }
          }
        }
      },
      "ModelsLegacyResponse": {
        "type": "object",
        "properties": {
          "models": {
            "type": "array",
            "description": "List of available model names",
            "items": {
              "type": "string",
              "description": "Model identifier",
              "example": "chatgpt-4o-latest"
            }
          }
        }
      },
      "BalanceResponse": {
        "type": "object",
        "properties": {
          "usd_balance": {
            "type": "string",
            "description": "Account balance in USD",
            "example": "129.46956147"
          },
          "nano_balance": {
            "type": "string",
            "description": "Account balance in Nano",
            "example": "26.71801147"
          },
          "nanoDepositAddress": {
            "type": "string",
            "description": "Nano deposit address for the account",
            "example": "nano_1gx385nnj7rw67hsksa3pyxwnfr48zu13t35ncjmtnqb9zdebtjhh7ahks34"
          }
        }
      },
      "ReceiveNanoResponse": {
        "type": "object",
        "properties": {
          "success": {
            "type": "boolean",
            "description": "Whether the operation was successful"
          },
          "received_blocks": {
            "type": "array",
            "description": "Array of received block hashes",
            "items": {
              "type": "string"
            }
          },
          "total_received": {
            "type": "string",
            "description": "Total amount of Nano received"
          }
        }
      },
      "VideoGenerationRequest": {
        "type": "object",
        "required": ["model"],
        "properties": {
          "model": {
            "type": "string",
            "description": "The video model to use for generation",
            "enum": [
              "longstories",
              "longstories-kids", 
              "kling-video",
              "kling-video-v2",
              "veo2-video",
              "minimax-video",
              "hunyuan-video",
              "hunyuan-video-image-to-video",
              "wan-video-image-to-video",
              "kling-v21-standard",
              "kling-v21-pro", 
              "kling-v21-master",
              "promptchan-video"
            ],
            "default": "longstories"
          },
          "prompt": {
            "type": "string",
            "description": "Text prompt describing the video to generate",
            "example": "A serene lake at sunset with gentle ripples on the water"
          },
          "script": {
            "type": "string",
            "description": "Fully-written script for LongStories models (takes precedence over prompt)"
          },
          "conversationUUID": {
            "type": "string",
            "description": "UUID for conversation tracking"
          },
          "projectId": {
            "type": "string",
            "description": "Project identifier for LongStories models"
          },
          "framework": {
            "type": "string",
            "description": "Story framework for LongStories models",
            "enum": ["default", "emotional_story", "product_showcase", "tutorial"],
            "default": "default"
          },
          "shortRequestEnhancer": {
            "type": "boolean",
            "description": "Smart Enhancement: if true, automatically choose better framework and add Director Notes if necessary",
            "default": false
          },
          "targetLengthInWords": {
            "type": "integer",
            "description": "Target length in words for LongStories models (legacy parameter)",
            "default": 70
          },
          "targetLengthInSeconds": {
            "type": "integer",
            "description": "Target length in seconds (alternative to words)"
          },
          "directorNotes": {
            "type": "string",
            "description": "Prompt for the image generation engine (LongStories). Example: 'Warm lighting' or 'Make the first image very impactful'",
            "example": "Warm, cozy lighting with focus on people interacting"
          },
          "aspectRatio": {
            "type": "string",
            "description": "Video aspect ratio for LongStories",
            "enum": ["9:16", "16:9"],
            "default": "9:16"
          },
          "scriptConfig": {
            "type": "object",
            "description": "Script generation configuration for LongStories",
            "properties": {
              "style": {
                "type": "string",
                "description": "Sets the tone & voice of the generated script",
                "enum": [
                  "default", "no_style", "engaging_conversational", "dixit_biography", 
                  "kind_biography", "hero_journey", "emotional_story", "dramatic_reveal",
                  "heartwarming_stories", "educational_history", "news_brief"
                ],
                "default": "default"
              },
              "targetLengthInSeconds": {
                "type": "integer",
                "description": "Approx. time length of the script in seconds. The actual length may vary slightly.",
                "minimum": 5,
                "maximum": 600,
                "default": 30
              }
            }
          },
          "imageConfig": {
            "type": "object",
            "description": "Image generation configuration for LongStories",
            "properties": {
              "model": {
                "type": "string",
                "description": "Which image model to use for generating images",
                "enum": [
                  "flux_schnell", "flux_lora", "flux_pro", "flux_pro_ultra", "recraft",
                  "sdxl", "sdxl_lora", "sd35_large", "sd35_medium", "sd35_large_turbo",
                  "leonardo_flux_precision", "leonardo_phoenix_quality", "leonardo_phoenix_ultra",
                  "reve-v1", "hidream_fast", "hidream_dev", "hidream_full", "gpt_image_1",
                  "imagen4_preview", "midjourney"
                ],
                "default": "hidream_dev"
              },
              "loraConfig": {
                "type": "object",
                "description": "Style configuration (only applies when using Flux LoRA model)",
                "properties": {
                  "loraSlug": {
                    "type": "string",
                    "description": "Specialized style to apply",
                    "enum": [
                      "ghibsky-comic-book", "colour-sketches", "sketch-paint", "90s-anime",
                      "2000s-crime-thrillers", "xno-symbol-flux"
                    ],
                    "default": "ghibsky-comic-book"
                  }
                }
              }
            }
          },
          "videoConfig": {
            "type": "object",
            "description": "Video generation configuration for LongStories",
            "properties": {
              "enabled": {
                "type": "boolean",
                "description": "Generate video motion from images instead of using static images",
                "default": true
              },
              "model": {
                "type": "string",
                "description": "Which video model to use for motion generation",
                "enum": [
                  "ltx_video_13b_distilled", "ltx_video", "stable_video", "motion",
                  "kling_v1_6_std_5s", "kling_v2_1_std_5s", "ltx_video_13b_dev", "skyreels",
                  "vidu", "kling_v1_6_std_10s", "kling_v2_1_std_10s", "kling_v2_1_pro_5s",
                  "luma_ray2", "kling_pro_5s", "minimax", "wan_i2v", "motion_2",
                  "kling_v2_1_pro_10s", "wan_pro", "luma_ray2_hd", "kling_pro_10s",
                  "kling_v2_1_master_5s", "kling_v2_master_5s", "veo2", "kling_v2_1_master_10s",
                  "kling_v2_master_10s"
                ],
                "default": "kling_v2_1_std_5s"
              }
            }
          },
          "voiceoverConfig": {
            "type": "object",
            "description": "Voiceover configuration for LongStories",
            "properties": {
              "enabled": {
                "type": "boolean",
                "description": "Enable AI voiceover for the video",
                "default": true
              },
              "voiceId": {
                "type": "string",
                "description": "Voice for video narration",
                "enum": [
                  "9BWtsMINqrJLrRacOk9x", "CwhRBWXzGAHq8TQ4Fs17", "EXAVITQu4vr4xnSDxMaL",
                  "FGY2WhTYpPnrIDTdsKH5", "IKne3meq5aSn9XLyUdCD", "JBFqnCBsd6RMkjVDRZzb",
                  "N2lVS1w4EtoT3dr4eOWO", "SAz9YHcvj6GT2YYXdXww", "TX3LPaxmHKxFdv7VOQHJ",
                  "XB0fDUnXU5powFXDhCwa", "Xb7hH8MSUJpSbSDYk0k2", "XrExE9yKIg1WjnnlVkGX",
                  "bIHbv24MWmeRgasZH58o", "cgSgspJ2msm6clMCkdW9", "cjVigY5qzO86Huf0OWal",
                  "nPczCjzI2devNBz1zQrb", "onwK4e9ZLuTAKqWW03F9", "pqHfZKP75CvOlQylNhV4",
                  "pFZP5JQG7iQjIQuC4Bku", "KHCvMklQZZo0O30ERnVn", "Nh2zY9kknu6z4pZy6FhD",
                  "LlZr3QuzbW4WrPjgATHG", "YExhVa4bZONzeingloMX", "m1VE7dnwBN0zMer3LcKv",
                  "zWDA589rUKXuLnPRDtAG", "YYHkBdgrAwQWIaH6m2ai"
                ],
                "default": "zWDA589rUKXuLnPRDtAG"
              }
            }
          },
          "captionsConfig": {
            "type": "object",
            "description": "Captions configuration for LongStories",
            "properties": {
              "captionsEnabled": {
                "type": "boolean",
                "description": "Show text captions in the video",
                "default": true
              },
              "captionsStyle": {
                "type": "string",
                "description": "Style of video captions",
                "enum": [
                  "default", "minimal", "neon", "cinematic", "fancy", "tiktok", "highlight",
                  "gradient", "intellectual", "vida", "manuscripts", "subtitle", "modern",
                  "bounce", "popcorn", "typewriter", "handwritten", "karaoke", "retro", "gaming"
                ],
                "default": "tiktok"
              }
            }
          },
          "effectsConfig": {
            "type": "object",
            "description": "Effects configuration for LongStories",
            "properties": {
              "transition": {
                "type": "string",
                "description": "Transition style between different images",
                "enum": ["fade", "random", "slide", "wipe", "flip", "none"],
                "default": "fade"
              },
              "floating": {
                "type": "boolean",
                "description": "Make the images move around slightly with floating effects",
                "default": true
              }
            }
          },
          "musicConfig": {
            "type": "object",
            "description": "Music configuration for LongStories",
            "properties": {
              "enabled": {
                "type": "boolean",
                "description": "Add background music to the video",
                "default": true
              },
              "musicSlug": {
                "type": "string",
                "description": "Choose background music for your video",
                "enum": [
                  "", "temple_of_treasures", "gentle_ambient_loop", "serene_ambience",
                  "soothing_ambience", "soothing_ambient_backdrop", "tranquil_ambience",
                  "dreamscape", "belonging_resonance", "vivid_memories", "cinematic_intro",
                  "cinematic_teaser", "dramatic_cinematic_score", "thriller_cinema_trailer",
                  "fractured_paintings", "promise_of_tomorrow", "spooky_orchestral_theme",
                  "light_upbeat_melody", "puzzle_time", "stomping_drums_rhythm",
                  "stomps_and_claps_rhythm_track", "news_theme", "adventurous_intro",
                  "burlesque_sweetheart", "highway_nocturne_national_sweetheart", "haptic_sensation"
                ],
                "default": "gentle_ambient_loop"
              },
              "volume": {
                "type": "number",
                "description": "Volume level for background music",
                "minimum": 0,
                "maximum": 1,
                "default": 0.3
              },
              "loop": {
                "type": "boolean",
                "description": "Whether to loop the background music",
                "default": true
              }
            }
          },
          "voice": {
            "type": "string",
            "description": "Legacy: Voice ID for narration (use voiceoverConfig.voiceId instead)",
            "example": "pNInz6obpgDQGcFmaJgB"
          },
          "captionsShow": {
            "type": "boolean",
            "description": "Legacy: Whether to show captions (use captionsConfig.captionsEnabled instead)",
            "default": true
          },
          "captionsStyle": {
            "type": "string",
            "description": "Legacy: Style for captions (use captionsConfig.captionsStyle instead)",
            "enum": ["default", "minimal", "neon", "cinematic", "fancy", "tiktok", "highlight", "gradient", "instagram", "vida", "manuscripts"],
            "default": "default"
          },
          "effects": {
            "type": "object",
            "description": "Legacy: Video effects configuration (use effectsConfig instead)",
            "properties": {
              "transition": {
                "type": "string",
                "default": "fade"
              },
              "floating": {
                "type": "boolean",
                "default": false
              }
            }
          },
          "quality": {
            "type": "string",
            "description": "Legacy: Video quality (handled by videoConfig now)",
            "enum": ["low", "medium", "high"],
            "default": "medium"
          },
          "motion": {
            "type": "object",
            "description": "Legacy: Motion configuration (handled by videoConfig now)",
            "properties": {
              "enabled": {
                "type": "boolean",
                "default": false
              },
              "strength": {
                "type": "integer",
                "minimum": 1,
                "maximum": 10,
                "default": 3
              }
            }
          },
          "music": {
            "type": "string",
            "description": "Legacy: Music track (use musicConfig instead)",
            "example": "video-creation/music/dramatic_cinematic_score.mp3"
          },
          "duration": {
            "oneOf": [
              {"type": "string"},
              {"type": "integer"}
            ],
            "description": "Video duration (format varies by model - '5s' for Veo2, '5' for Kling, etc.)",
            "example": "5s"
          },
          "aspect_ratio": {
            "type": "string",
            "description": "Aspect ratio for FAL models",
            "enum": ["16:9", "9:16", "1:1", "4:3", "3:4"],
            "default": "16:9"
          },
          "negative_prompt": {
            "type": "string",
            "description": "Negative prompt to avoid certain elements",
            "example": "blur, distort, and low quality"
          },
          "cfg_scale": {
            "type": "number",
            "description": "Classifier-free guidance scale",
            "minimum": 0,
            "maximum": 20,
            "default": 0.5
          },
          "imageDataUrl": {
            "type": "string",
            "description": "Base64 data URL of input image for image-to-video models"
          },
          "imageAttachmentId": {
            "type": "string", 
            "description": "Library attachment ID for input image"
          },
          "prompt_optimizer": {
            "type": "boolean",
            "description": "Whether to optimize the prompt (MiniMax model)",
            "default": true
          },
          "num_inference_steps": {
            "type": "integer",
            "description": "Number of inference steps",
            "minimum": 1,
            "maximum": 50,
            "default": 30
          },
          "pro_mode": {
            "type": "boolean",
            "description": "Enable pro mode for Hunyuan Video",
            "default": false
          },
          "resolution": {
            "type": "string",
            "description": "Video resolution",
            "enum": ["720p", "1080p", "540p"],
            "default": "720p"
          },
          "num_frames": {
            "oneOf": [
              {"type": "integer"},
              {"type": "string"}
            ],
            "description": "Number of frames to generate",
            "default": 81
          },
          "frames_per_second": {
            "type": "integer",
            "description": "Frames per second",
            "minimum": 5,
            "maximum": 24,
            "default": 16
          },
          "seed": {
            "type": "integer",
            "description": "Random seed for reproducible results"
          },
          "enable_safety_checker": {
            "type": "boolean",
            "description": "Enable safety content filtering",
            "default": true
          },
          "showExplicitContent": {
            "type": "boolean",
            "description": "Allow explicit content (inverse of safety checker)",
            "default": false
          },
          "enable_prompt_expansion": {
            "type": "boolean",
            "description": "Enable automatic prompt expansion"
          },
          "acceleration": {
            "type": "boolean",
            "description": "Enable acceleration for faster processing"
          },
          "shift": {
            "type": "number",
            "description": "Shift parameter for certain models"
          },
          "age_slider": {
            "type": "integer",
            "description": "Age setting for PromptChan model",
            "minimum": 18,
            "maximum": 60,
            "default": 18
          },
          "audioEnabled": {
            "type": "boolean",
            "description": "Enable audio for PromptChan model",
            "default": false
          },
          "video_quality": {
            "type": "string",
            "description": "Video quality for PromptChan model",
            "enum": ["Standard", "High"],
            "default": "Standard"
          },
          "aspect": {
            "type": "string",
            "description": "Aspect setting for PromptChan model",
            "enum": ["Portrait", "Landscape", "Square"],
            "default": "Portrait"
          }
        }
      },
      "VideoGenerationResponse": {
        "type": "object",
        "required": ["runId", "status", "model"],
        "properties": {
          "runId": {
            "type": "string",
            "description": "Unique identifier for the video generation request"
          },
          "projectId": {
            "type": "string",
            "description": "Project identifier (for LongStories models)"
          },
          "status": {
            "type": "string",
            "description": "Current status of the generation",
            "enum": ["pending", "processing", "completed", "failed"],
            "default": "pending"
          },
          "model": {
            "type": "string",
            "description": "The model used for generation"
          },
          "cost": {
            "type": "number",
            "description": "Cost of the video generation"
          },
          "paymentSource": {
            "type": "string",
            "description": "Payment source used (USD or XNO)"
          },
          "remainingBalance": {
            "type": "number",
            "description": "Remaining balance after the generation"
          }
        }
      },
      "VideoStatusResponse": {
        "type": "object",
        "properties": {
          "status": {
            "type": "string",
            "description": "Current status of the generation",
            "enum": ["PENDING", "PROCESSING", "COMPLETED", "FAILED"]
          },
          "data": {
            "type": "object",
            "properties": {
              "isCompleted": {
                "type": "boolean",
                "description": "Whether the generation is completed"
              },
              "isSuccess": {
                "type": "boolean",
                "description": "Whether the generation was successful"
              },
              "output": {
                "type": "object",
                "properties": {
                  "url": {
                    "type": "string",
                    "description": "URL to the generated video"
                  }
                }
              }
            }
          }
        }
      },
      "CheckMidjourneyStatusRequest": {
        "type": "object",
        "required": ["task_id"],
        "properties": {
          "task_id": {
            "type": "string",
            "description": "The unique identifier for the Midjourney generation task.",
            "example": "1744449927914205"
          }
        }
      },
      "CheckMidjourneyStatusResponse": {
        "type": "object",
        "required": ["status", "task_id"],
        "properties": {
          "status": {
            "type": "string",
            "description": "The current status of the Midjourney task.",
            "enum": ["SUCCESS", "FAILED", "PENDING", "RUNNING", "IN_PROGRESS", "submitted", "NOT_START", "unknown"],
            "example": "SUCCESS"
          },
          "task_id": {
            "type": "string",
            "description": "The unique identifier for the Midjourney generation task.",
            "example": "1744449927914205"
          },
          "progress": {
            "type": "string",
            "description": "Optional progress indicator (e.g., \"0%\")",
            "example": "50%",
            "nullable": true
          },
          "imageUrl": {
            "type": "string",
            "format": "uri",
            "description": "The URL of the generated image (present on SUCCESS).",
            "example": "https://image-url.com/generated_image.png",
            "nullable": true
          },
          "failReason": {
            "type": "string",
            "description": "The reason for failure (present on FAILED).",
            "example": "Content moderation filter triggered.",
            "nullable": true
          }
        }
      },
      "OpenAIImageGenerationsRequest": {
        "type": "object",
        "required": [
          "prompt"
        ],
        "properties": {
          "model": {
            "type": "string",
            "description": "The model to use for generation",
            "default": "hidream"
          },
          "prompt": {
            "type": "string",
            "description": "The text prompt to generate an image from"
          },
          "n": {
            "type": "integer",
            "description": "Number of images to generate",
            "default": 1
          },
          "size": {
            "type": "string",
            "description": "The size of the generated images",
            "enum": ["256x256", "512x512", "1024x1024"]
          },
          "response_format": {
            "type": "string",
            "description": "The format in which the generated images are returned",
            "enum": ["url", "b64_json"]
          },
          "user": {
            "type": "string",
            "description": "A unique identifier representing your end-user"
          }
        }
      },
      "OpenAIImageGenerationsResponse": {
        "type": "object",
        "properties": {
          "created": {
            "type": "integer",
            "description": "Unix timestamp of when the image was created"
          },
          "data": {
            "type": "array",
            "description": "List of generated images",
            "items": {
              "type": "object",
              "properties": {
                "url": { "type": "string", "description": "URL to the generated image" },
                "b64_json": { "type": "string", "description": "Base64 encoded image data" }
              }
            }
          },
          "cost": {
            "type": "number",
            "description": "Cost of the generation"
          },
          "paymentSource": {
            "type": "string",
            "description": "Payment source used"
          },
          "remainingBalance": {
            "type": "number",
            "description": "Remaining balance after the generation"
          }
        }
      },
      "TEEAttestationResponse": {
        "type": "object",
        "properties": {
          "attestation": {
            "type": "string",
            "description": "The attestation report"
          }
        }
      },
      "TEESignatureResponse": {
        "type": "object",
        "properties": {
          "signature": {
            "type": "string",
            "description": "The ECDSA signature"
          }
        }
      },
      "UnifiedVideoStatusResponse": {
        "type": "object",
        "required": [
          "requestId",
          "status",
          "videoUrl",
          "error",
          "createdAt",
          "completedAt"
        ],
        "properties": {
          "requestId": {
            "type": "string",
            "description": "The unique request ID for the video generation"
          },
          "status": {
            "type": "string",
            "description": "Current normalized status of the video generation",
            "enum": ["queued", "processing", "completed", "failed", "cancelled", "unknown"]
          },
          "progress": {
            "type": "number",
            "nullable": true,
            "description": "Generation progress as a percentage (0-100), if available"
          },
          "estimatedTimeRemaining": {
            "type": "number",
            "nullable": true,
            "description": "Estimated time remaining in seconds, if available"
          },
          "videoUrl": {
            "type": "string",
            "nullable": true,
            "description": "URL to the generated video (available when status is 'completed')"
          },
          "error": {
            "type": "string",
            "nullable": true,
            "description": "Error message if the generation failed"
          },
          "createdAt": {
            "type": "string",
            "nullable": true,
            "description": "ISO timestamp when the request was created"
          },
          "completedAt": {
            "type": "string",
            "nullable": true,
            "description": "ISO timestamp when the generation completed"
          }
        }
      },
      "TranscribeFormRequest": {
        "type": "object",
        "properties": {
          "audio": {
            "type": "string",
            "format": "binary",
            "description": "Direct file upload (max 3MB). Supported formats: MP3, WAV, M4A, OGG, AAC"
          },
          "audioUrl": {
            "type": "string",
            "format": "uri",
            "description": "URL to audio file (alternative to direct upload, supports up to 500MB)"
          },
          "model": {
            "type": "string",
            "description": "The STT model to use for transcription",
            "enum": ["Whisper-Large-V3", "Wizper", "Elevenlabs-STT"],
            "default": "Whisper-Large-V3"
          },
          "language": {
            "type": "string",
            "description": "Language code for transcription (ISO 639-1 or ISO 639-3). Use 'auto' for auto-detection",
            "default": "auto",
            "example": "en"
          },
          "actualDuration": {
            "type": "string",
            "description": "Actual audio duration in minutes for accurate billing"
          },
          "diarize": {
            "type": "string",
            "description": "Enable speaker diarization (Elevenlabs-STT only)",
            "enum": ["true", "false"],
            "default": "false"
          },
          "tagAudioEvents": {
            "type": "string",
            "description": "Tag non-speech audio events like [laughter], [applause] (Elevenlabs-STT only)",
            "enum": ["true", "false"],
            "default": "false"
          }
        }
      },
      "TranscribeJsonRequest": {
        "type": "object",
        "properties": {
          "audioUrl": {
            "type": "string",
            "format": "uri",
            "description": "URL to audio file to transcribe",
            "example": "https://example.com/audio.mp3"
          },
          "model": {
            "type": "string",
            "description": "The STT model to use for transcription",
            "enum": ["Whisper-Large-V3", "Wizper", "Elevenlabs-STT"],
            "default": "Whisper-Large-V3"
          },
          "language": {
            "type": "string",
            "description": "Language code for transcription (ISO 639-1 or ISO 639-3). Use 'auto' for auto-detection",
            "default": "auto",
            "example": "en"
          },
          "actualDuration": {
            "type": "string",
            "description": "Actual audio duration in minutes for accurate billing"
          },
          "diarize": {
            "type": "boolean",
            "description": "Enable speaker diarization (Elevenlabs-STT only)",
            "default": false
          },
          "tagAudioEvents": {
            "type": "boolean",
            "description": "Tag non-speech audio events like [laughter], [applause] (Elevenlabs-STT only)",
            "default": false
          }
        },
        "required": ["audioUrl"]
      },
      "TranscribeResponse": {
        "type": "object",
        "required": ["transcription", "metadata"],
        "properties": {
          "transcription": {
            "type": "string",
            "description": "The transcribed text",
            "example": "Hello, this is a test transcription."
          },
          "metadata": {
            "type": "object",
            "required": ["model", "cost", "currency"],
            "properties": {
              "fileName": {
                "type": "string",
                "description": "Original file name"
              },
              "fileSize": {
                "type": "integer",
                "description": "File size in bytes"
              },
              "chargedDuration": {
                "type": "number",
                "description": "Duration charged for billing (in minutes)"
              },
              "actualDuration": {
                "type": "number",
                "description": "Actual audio duration (in minutes)"
              },
              "language": {
                "type": "string",
                "description": "Detected or specified language code"
              },
              "cost": {
                "type": "number",
                "description": "Cost of the transcription"
              },
              "currency": {
                "type": "string",
                "description": "Currency of the cost",
                "default": "USD"
              },
              "model": {
                "type": "string",
                "description": "Model used for transcription"
              }
            }
          }
        }
      },
      "TranscribeAsyncResponse": {
        "type": "object",
        "required": ["runId", "status", "model"],
        "properties": {
          "runId": {
            "type": "string",
            "description": "Unique identifier for the transcription job",
            "example": "abc123def456"
          },
          "status": {
            "type": "string",
            "description": "Current status of the transcription job",
            "enum": ["pending", "processing", "completed", "failed"],
            "default": "pending"
          },
          "model": {
            "type": "string",
            "description": "Model used for transcription"
          },
          "cost": {
            "type": "number",
            "description": "Cost of the transcription"
          },
          "paymentSource": {
            "type": "string",
            "description": "Payment source used (USD or XNO)"
          },
          "isApiRequest": {
            "type": "boolean",
            "description": "Whether this is an API request"
          },
          "fileName": {
            "type": "string",
            "description": "Original file name"
          },
          "fileSize": {
            "type": "integer",
            "description": "File size in bytes"
          },
          "chargedDuration": {
            "type": "number",
            "description": "Duration charged for billing (in minutes)"
          },
          "diarize": {
            "type": "boolean",
            "description": "Whether speaker diarization is enabled"
          }
        }
      },
      "TranscribeStatusRequest": {
        "type": "object",
        "required": ["runId"],
        "properties": {
          "runId": {
            "type": "string",
            "description": "Unique identifier for the transcription job",
            "example": "abc123def456"
          },
          "cost": {
            "type": "number",
            "description": "Cost of the transcription (from initial response)"
          },
          "paymentSource": {
            "type": "string",
            "description": "Payment source used (from initial response)"
          },
          "isApiRequest": {
            "type": "boolean",
            "description": "Whether this is an API request (from initial response)"
          },
          "fileName": {
            "type": "string",
            "description": "Original file name (from initial response)"
          },
          "fileSize": {
            "type": "integer",
            "description": "File size in bytes (from initial response)"
          },
          "chargedDuration": {
            "type": "number",
            "description": "Duration charged for billing (from initial response)"
          },
          "diarize": {
            "type": "boolean",
            "description": "Whether speaker diarization is enabled (from initial response)"
          }
        }
      },
      "TranscribeStatusResponse": {
        "type": "object",
        "required": ["status"],
        "properties": {
          "status": {
            "type": "string",
            "description": "Current status of the transcription job",
            "enum": ["pending", "processing", "completed", "failed"]
          },
          "transcription": {
            "type": "string",
            "description": "The transcribed text (available when status is 'completed')",
            "example": "Speaker 1: Hello everyone. Speaker 2: Hi there!"
          },
          "metadata": {
            "type": "object",
            "description": "Transcription metadata (available when status is 'completed')",
            "properties": {
              "fileName": {
                "type": "string",
                "description": "Original file name"
              },
              "fileSize": {
                "type": "integer",
                "description": "File size in bytes"
              },
              "chargedDuration": {
                "type": "number",
                "description": "Duration charged for billing (in minutes)"
              },
              "actualDuration": {
                "type": "number",
                "description": "Actual audio duration (in minutes)"
              },
              "language": {
                "type": "string",
                "description": "Detected language code"
              },
              "cost": {
                "type": "number",
                "description": "Cost of the transcription"
              },
              "currency": {
                "type": "string",
                "description": "Currency of the cost"
              },
              "model": {
                "type": "string",
                "description": "Model used for transcription"
              }
            }
          },
          "words": {
            "type": "array",
            "description": "Word-level timestamps and speaker information (Elevenlabs-STT only)",
            "items": {
              "type": "object",
              "properties": {
                "text": {
                  "type": "string",
                  "description": "The word or text segment"
                },
                "start": {
                  "type": "number",
                  "description": "Start time in seconds"
                },
                "end": {
                  "type": "number",
                  "description": "End time in seconds"
                },
                "type": {
                  "type": "string",
                  "description": "Type of segment",
                  "enum": ["word", "punctuation"]
                },
                "speaker_id": {
                  "type": "string",
                  "description": "Speaker identifier (when diarization is enabled)"
                }
              }
            }
          },
          "diarization": {
            "type": "object",
            "description": "Speaker diarization results (when enabled)",
            "properties": {
              "segments": {
                "type": "array",
                "description": "Speaker segments with timestamps",
                "items": {
                  "type": "object",
                  "properties": {
                    "speaker": {
                      "type": "string",
                      "description": "Speaker label (e.g., 'Speaker 1')"
                    },
                    "text": {
                      "type": "string",
                      "description": "Text spoken by this speaker"
                    },
                    "start": {
                      "type": "number",
                      "description": "Start time in seconds"
                    },
                    "end": {
                      "type": "number",
                      "description": "End time in seconds"
                    }
                  }
                }
              }
            }
          },
          "error": {
            "type": "string",
            "description": "Error message (available when status is 'failed')"
          }
        }
      },
      "TTSRequest": {
        "type": "object",
        "required": ["text"],
        "properties": {
          "text": {
            "type": "string",
            "description": "The text to convert to speech",
            "example": "Hello! This is a test of the text-to-speech API."
          },
          "model": {
            "type": "string",
            "description": "The TTS model to use for generation",
            "enum": ["Kokoro-82m", "Dia-TTS", "Elevenlabs-Turbo-V2.5", "tts-1", "tts-1-hd", "gpt-4o-mini-tts"],
            "default": "Kokoro-82m"
          },
          "voice": {
            "type": "string",
            "description": "The voice to use for synthesis (available voices depend on selected model)",
            "example": "af_bella"
          },
          "speed": {
            "type": "number",
            "description": "Speech speed multiplier (0.1-5, not supported for gpt-4o-mini-tts)",
            "minimum": 0.1,
            "maximum": 5,
            "default": 1
          },
          "response_format": {
            "type": "string",
            "description": "Audio output format (OpenAI models only)",
            "enum": ["mp3", "opus", "aac", "flac", "wav", "pcm"],
            "default": "mp3"
          },
          "instructions": {
            "type": "string",
            "description": "Voice instructions for fine-tuning (gpt-4o-mini-tts and tts-1-hd only)",
            "example": "speak with enthusiasm"
          },
          "stability": {
            "type": "number",
            "description": "Voice stability (Elevenlabs-Turbo-V2.5 only, 0-1)",
            "minimum": 0,
            "maximum": 1,
            "default": 0.5
          },
          "similarity_boost": {
            "type": "number",
            "description": "Voice similarity boost (Elevenlabs-Turbo-V2.5 only, 0-1)",
            "minimum": 0,
            "maximum": 1,
            "default": 0.75
          },
          "style": {
            "type": "number",
            "description": "Style exaggeration (Elevenlabs-Turbo-V2.5 only, 0-1)",
            "minimum": 0,
            "maximum": 1,
            "default": 0
          }
        }
      },
      "TTSResponse": {
        "type": "object",
        "properties": {
          "audioUrl": {
            "type": "string",
            "format": "uri",
            "description": "URL to the generated audio file",
            "example": "https://storage.url/audio-file.wav"
          },
          "contentType": {
            "type": "string",
            "description": "MIME type of the audio file",
            "example": "audio/wav"
          },
          "model": {
            "type": "string",
            "description": "Model used for generation"
          },
          "text": {
            "type": "string",
            "description": "The input text that was synthesized"
          },
          "voice": {
            "type": "string",
            "description": "Voice used for synthesis"
          },
          "speed": {
            "type": "number",
            "description": "Speed multiplier used"
          },
          "duration": {
            "type": "number",
            "description": "Duration of the generated audio in seconds"
          },
          "cost": {
            "type": "number",
            "description": "Cost of the generation"
          },
          "currency": {
            "type": "string",
            "description": "Currency of the cost"
          }
        }
      },
      "YouTubeTranscribeRequest": {
        "type": "object",
        "required": ["urls"],
        "properties": {
          "urls": {
            "type": "array",
            "description": "Array of YouTube URLs to transcribe (maximum 10 URLs per request)",
            "items": {
              "type": "string",
              "format": "uri",
              "description": "YouTube URL in supported format"
            },
            "minItems": 1,
            "maxItems": 10,
            "example": [
              "https://www.youtube.com/watch?v=dQw4w9WgXcQ",
              "https://youtu.be/kJQP7kiw5Fk"
            ]
          }
        }
      },
      "YouTubeTranscribeResponse": {
        "type": "object",
        "required": ["transcripts", "summary"],
        "properties": {
          "transcripts": {
            "type": "array",
            "description": "Array of transcript results for each URL",
            "items": {
              "type": "object",
              "required": ["url", "success"],
              "properties": {
                "url": {
                  "type": "string",
                  "description": "The original YouTube URL"
                },
                "success": {
                  "type": "boolean",
                  "description": "Whether the transcript was successfully retrieved"
                },
                "title": {
                  "type": "string",
                  "description": "Video title (only if successful)"
                },
                "transcript": {
                  "type": "string",
                  "description": "The full transcript text (only if successful)"
                },
                "error": {
                  "type": "string",
                  "description": "Error message (only if failed)"
                }
              }
            }
          },
          "summary": {
            "type": "object",
            "required": ["requested", "processed", "successful", "failed", "totalCost"],
            "properties": {
              "requested": {
                "type": "integer",
                "description": "Number of URLs provided in the request"
              },
              "processed": {
                "type": "integer",
                "description": "Number of valid YouTube URLs found and processed"
              },
              "successful": {
                "type": "integer",
                "description": "Number of transcripts successfully retrieved"
              },
              "failed": {
                "type": "integer",
                "description": "Number of transcripts that failed"
              },
              "totalCost": {
                "type": "number",
                "description": "Total cost in USD for successful transcripts"
              }
            }
          }
        }
      }
    },
    "securitySchemes": {
      "bearerAuth": {
        "type": "http",
        "scheme": "bearer"
      },
      "apiKeyAuth": {
        "type": "apiKey",
        "in": "header",
        "name": "x-api-key"
      }
    }
  }
}